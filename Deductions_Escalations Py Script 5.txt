import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import datetime
import numpy as np
import os
import sys
import json
from io import BytesIO, StringIO

# Define themes
THEMES = {
    "Default": {
        "primary_color": "#1E88E5",
        "background_color": "#FFFFFF",
        "text_color": "#424242",
        "accent_color": "#FFC107",
        "secondary_color": "#4CAF50",
        "font": "sans-serif"
    },
    "Dark": {
        "primary_color": "#2962FF",
        "background_color": "#121212",
        "text_color": "#E0E0E0",
        "accent_color": "#FF6D00",
        "secondary_color": "#00C853",
        "font": "sans-serif"
    },
    "Corporate": {
        "primary_color": "#0D47A1",
        "background_color": "#F5F5F5",
        "text_color": "#212121",
        "accent_color": "#E65100",
        "secondary_color": "#2E7D32",
        "font": "serif"
    }
}

# Apply theme
def apply_theme(theme_name):
    if theme_name not in THEMES:
        theme_name = "Default"
    
    theme = THEMES[theme_name]
    
    # Apply CSS with the selected theme
    st.markdown(f"""
<style>
        /* Global Styles */
        .stApp {{
            background-color: {theme["background_color"]};
            color: {theme["text_color"]};
            font-family: {theme["font"]};
        }}
        
        /* Headers */
        h1, h2, h3, h4, h5, h6 {{
            color: {theme["primary_color"]};
            font-family: {theme["font"]};
        }}
        
        /* Main title */
        .main-title {{
            color: {theme["primary_color"]};
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 1rem;
            text-align: center;
            padding: 1rem;
            border-bottom: 2px solid {theme["accent_color"]};
        }}
        
        /* Sub titles */
        .sub-title {{
            color: {theme["primary_color"]};
            font-size: 1.5rem;
            font-weight: 600;
            margin-top: 1rem;
            margin-bottom: 0.5rem;
            padding-bottom: 0.3rem;
            border-bottom: 1px solid {theme["accent_color"]}40;
        }}
    </style>
    """, unsafe_allow_html=True)

# Create session state for user preferences if not exists
if 'theme' not in st.session_state:
    st.session_state['theme'] = "Default"

# Check authentication status
if "authenticated" not in st.session_state or not st.session_state["authenticated"]:
    st.warning("Please log in from the Home page to access this dashboard.")
    st.stop()

# Create a minimal sidebar with just welcome message
with st.sidebar:
    # Debug section (collapsible)
    with st.expander("Debug Info", expanded=False):
        if 'debug_messages' in st.session_state:
            for msg in st.session_state.debug_messages[-10:]:  # Show last 10 messages
                st.text(msg)
        else:
            st.text("No debug messages yet")
            
    # Welcome Message
    st.markdown(f"<div class='welcome-header'>Welcome, {st.session_state.get('username', 'User')}</div>", unsafe_allow_html=True)
    
    # Add a separator
    st.markdown("---")

# Apply the current theme
apply_theme(st.session_state['theme'])

# Initialize session state for storing the dataframe
if 'deductions_df' not in st.session_state:
    st.session_state['deductions_df'] = None
    st.session_state['file_processed'] = False

def debug_print(message):
    """Print debug messages to both console and sidebar if enabled"""
    # Always print to console
    print(f"[DEBUG] {message}")
    
    # Also show in the Streamlit app's debug section
    if 'debug_messages' not in st.session_state:
        st.session_state.debug_messages = []
    st.session_state.debug_messages.append(str(message))
    
    # Keep only the last 20 messages
    if len(st.session_state.debug_messages) > 20:
        st.session_state.debug_messages = st.session_state.debug_messages[-20:]

def convert_to_numeric(series):
    """Helper function to safely convert series to numeric"""
    # If already numeric, return as is
    if pd.api.types.is_numeric_dtype(series):
        return series
    
    # Try to convert to string first to handle any non-string types
    str_series = series.astype(str)
    
    # Remove any non-numeric characters except decimal point and negative sign
    cleaned = str_series.str.replace(r'[^\d.-]', '', regex=True)
    
    # Convert to numeric, coercing errors to NaN
    return pd.to_numeric(cleaned, errors='coerce')

def process_uploaded_file(uploaded_file):
    """Process the uploaded file and return a cleaned dataframe"""
    try:
        # Read the file
        if uploaded_file.name.endswith('.xlsx') or uploaded_file.name.endswith('.xls'):
            df = pd.read_excel(uploaded_file, engine='openpyxl')
        else:
            df = pd.read_csv(uploaded_file)
        
        # Store original columns before any processing
        original_columns = df.columns.tolist()
        debug_print(f"Original columns: {original_columns}")
        
        # First, clean up the column names (just trim whitespace, no title case conversion)
        df.columns = df.columns.str.strip()
        cleaned_columns = df.columns.tolist()
        debug_print(f"Cleaned columns: {cleaned_columns}")
        
        # Define expected columns with possible variations (exact matches)
        column_mapping = {
            "Environment": ["Environment"],
            "Deduction Submission Date": ["Deduction Submission Date"],
            "BranchID": ["BranchID"],
            "Employer": ["Employer"],
            "DepartmentName": ["DepartmentName"],
            "Pay Day": ["Pay Day"],
            "Provider": ["Provider"],
            "Method": ["Method"],
            "Transactions": ["Transactions"],
            "Amount": ["Amount"],
            "Failed Amount": ["Failed Amount"],
            "Failed Department": ["Failed Department"],
            "Status": ["Status"],
            "Escalated To": ["Escalated To"],
            "Successful via Automation": ["Successful via Automation"],
            "Reason": ["Reason"],
            "Remarks": ["Remarks"],
            "Mode": ["Mode"],
            "Task Link / Email Subject": ["Task Link / Email Subject"]
        }
        
        # Create a mapping of cleaned column names to original names
        original_name_map = {col.strip(): col for col in original_columns}
        
        # Map actual columns to expected columns
        column_mapping_inv = {}
        mapped_columns = set()
        
        # First pass: exact matches
        for expected_col, possible_cols in column_mapping.items():
            for col in possible_cols:
                if col in df.columns:
                    column_mapping_inv[col] = expected_col
                    mapped_columns.add(col)
                    debug_print(f"Mapped '{col}' to '{expected_col}' (exact match)")
                    break
        
        # Second pass: case-insensitive matches for any remaining columns
        remaining_columns = [col for col in df.columns if col not in mapped_columns]
        debug_print(f"Remaining unmapped columns: {remaining_columns}")
        
        for col in remaining_columns:
            col_lower = col.lower().replace(" ", "").replace("_", "").replace("-", "")
            for expected_col in column_mapping.keys():
                expected_col_lower = expected_col.lower().replace(" ", "").replace("_", "").replace("-", "")
                if col_lower == expected_col_lower:
                    column_mapping_inv[col] = expected_col
                    mapped_columns.add(col)
                    debug_print(f"Mapped '{col}' to '{expected_col}' (case-insensitive match)")
                    break
        
        # Debug: Print the mapping
        debug_print(f"Column mapping: {column_mapping_inv}")
        
        # Rename columns to standard names
        if column_mapping_inv:
            df = df.rename(columns=column_mapping_inv)
        
        # Check for missing expected columns
        missing_columns = [col for col in column_mapping.keys() if col not in df.columns]
        if missing_columns:
            st.warning(f"Warning: The following columns could not be mapped: {', '.join(missing_columns)}")
            st.info(f"Available columns: {', '.join(original_columns)}")
        
        # Debug: Print final column names
        debug_print(f"Final column names: {df.columns.tolist()}")
        
        # Convert numeric columns
        numeric_columns = ["Amount", "Failed Amount", "Transactions"]
        for col in numeric_columns:
            if col in df.columns:
                df[col] = convert_to_numeric(df[col])
            else:
                debug_print(f"Numeric column not found: {col}")
        
        # Convert date columns
        date_columns = ["Deduction Submission Date", "Pay Day"]
        for col in date_columns:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col], errors='coerce')
            else:
                debug_print(f"Date column not found: {col}")
        
        return df
        
    except Exception as e:
        st.error(f"Error processing file: {str(e)}")
        debug_print(f"Error processing file: {str(e)}")
        return None

def safe_sum(series, default=0):
    """Safely sum a series, handling None and NaN values"""
    if series is None or series.empty or not pd.api.types.is_numeric_dtype(series):
        return default
    return series.sum()

def display_metrics(df):
    """Display key metrics from the dataframe"""
    if df is None or df.empty:
        st.warning("No data available to display metrics.")
        return
    
    # Safely calculate metrics with default values
    total_deductions = safe_sum(df.get('Amount'))
    total_failed = safe_sum(df.get('Failed Amount'))
    
    # Calculate failure rate safely
    if pd.notna(total_deductions) and total_deductions > 0 and pd.notna(total_failed):
        failure_rate = (total_failed / total_deductions) * 100
    else:
        failure_rate = 0.0
    
    # Format values for display
    def format_currency(value):
        try:
            return f"${float(value):,.2f}"
        except (ValueError, TypeError):
            return "$0.00"
    
    # Display metrics in columns with error handling
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Total Deductions", format_currency(total_deductions))
    with col2:
        st.metric("Total Failed", format_currency(total_failed))
    with col3:
        st.metric("Failure Rate", f"{failure_rate:.2f}%")

def main():
    st.markdown("<h1 class='main-title'>Deductions Escalations Dashboard</h1>", unsafe_allow_html=True)
    
    # File upload section
    st.markdown("### Upload Deductions Report")
    uploaded_file = st.file_uploader(
        "Upload your deductions report (Excel or CSV)",
        type=['xlsx', 'xls', 'csv'],
        key="deductions_uploader"
    )
    
    if uploaded_file is not None:
        with st.spinner('Processing file...'):
            # Process the file
            df = process_uploaded_file(uploaded_file)
            
            if df is not None:
                st.session_state['deductions_df'] = df
                st.session_state['file_processed'] = True
                st.success("File processed successfully!")
                
                # Display metrics
                display_metrics(df)
                
                # Show a preview of the data
                st.markdown("### Data Preview")
                st.dataframe(df.head())
    
    # If we have processed data, show the full dashboard
    if st.session_state.get('file_processed') and st.session_state['deductions_df'] is not None:
        df = st.session_state['deductions_df']
        
        # Add tabs for different views with clear separation of concerns
        tab1, tab2, tab3 = st.tabs(["📊 Overview", "🔍 Transaction Explorer", "📈 Advanced Analytics"])
        
        # Initialize session state for tab navigation
        if 'selected_provider' not in st.session_state:
            st.session_state.selected_provider = None
            st.session_state.force_explorer_refresh = False
        
        def navigate_to_explorer(provider=None):
            st.session_state.selected_provider = provider
            st.session_state.force_explorer_refresh = True
            # Store the current tab to return to after explorer
            st.session_state.previous_tab = "📊 Overview"
        
        with tab1:
            st.markdown("### 📊 Deductions Overview")
            
            # Date range filter
            st.markdown("#### Date Range Filter")
            if 'Deduction Submission Date' in df.columns:
                min_date = df['Deduction Submission Date'].min().date()
                max_date = df['Deduction Submission Date'].max().date()
                
                col1, col2 = st.columns(2)
                with col1:
                    start_date = st.date_input(
                        "Start Date",
                        min_value=min_date,
                        max_value=max_date,
                        value=min_date,
                        key="start_date"
                    )
                with col2:
                    end_date = st.date_input(
                        "End Date",
                        min_value=min_date,
                        max_value=max_date,
                        value=max_date,
                        key="end_date"
                    )
                
                # Filter data by date range
                date_mask = (
                    (df['Deduction Submission Date'].dt.date >= start_date) & 
                    (df['Deduction Submission Date'].dt.date <= end_date)
                )
                filtered_df = df[date_mask].copy()
            else:
                filtered_df = df.copy()
                st.warning("No date column found for filtering")
            
            # Top row with metrics
            st.markdown("#### Key Metrics")
            metric1, metric2, metric3, metric4 = st.columns(4)
            
            with metric1:
                total_deductions = filtered_df['Amount'].sum() if 'Amount' in filtered_df.columns else 0
                st.metric("Total Deductions", f"${total_deductions:,.2f}")
            
            with metric2:
                avg_deduction = filtered_df['Amount'].mean() if 'Amount' in filtered_df.columns else 0
                st.metric("Avg. Deduction", f"${avg_deduction:,.2f}")
            
            with metric3:
                total_failed = filtered_df['Failed Amount'].sum() if 'Failed Amount' in filtered_df.columns else 0
                st.metric("Total Failed", f"${total_failed:,.2f}")
            
            with metric4:
                failure_rate = (total_failed / total_deductions * 100) if total_deductions > 0 else 0
                st.metric("Failure Rate", f"{failure_rate:.2f}%")
            
            # First row of charts
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### Deductions Trend Analysis")
                if 'Deduction Submission Date' in filtered_df.columns and 'Amount' in filtered_df.columns:
                    # Daily, weekly, monthly aggregation
                    freq = st.radio("View by:", ["Daily", "Weekly", "Monthly"], horizontal=True, key="freq_radio")
                    freq_map = {"Daily": "D", "Weekly": "W-Mon", "Monthly": "M"}
                    
                    time_series = filtered_df.groupby(
                        pd.Grouper(key='Deduction Submission Date', freq=freq_map[freq])
                    )['Amount'].sum().reset_index()
                    
                    # Calculate moving average based on frequency
                    window = 4 if freq == "Monthly" else (2 if freq == "Weekly" else 7)
                    
                    fig = px.area(
                        time_series, 
                        x='Deduction Submission Date', 
                        y='Amount',
                        title=f'{freq} Deductions Trend',
                        labels={'Amount': 'Total Amount ($)', 'Deduction Submission Date': 'Date'},
                        template='plotly_white'
                    )
                    
                    # Add trendline
                    fig.add_scatter(
                        x=time_series['Deduction Submission Date'],
                        y=time_series['Amount'].rolling(window=min(window, len(time_series)), min_periods=1).mean(),
                        mode='lines',
                        name=f'{window}-Period Moving Avg',
                        line=dict(color='red', width=2, dash='dash')
                    )
                    
                    fig.update_layout(
                        hovermode='x unified',
                        showlegend=True,
                        xaxis_title=None,
                        yaxis_title='Amount ($)',
                        height=400
                    )
                    st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                st.markdown("#### Deductions by Status & Provider")
                if all(col in filtered_df.columns for col in ['Status', 'Amount', 'Provider']):
                    # Create a multi-level pie chart
                    tab1, tab2 = st.tabs(["By Status", "By Provider"])
                    
                    with tab1:
                        status_summary = filtered_df.groupby('Status')['Amount'].sum().reset_index()
                        fig2a = px.pie(
                            status_summary, 
                            values='Amount', 
                            names='Status',
                            title='Deductions by Status',
                            hole=0.4,
                            template='plotly_white'
                        )
                        st.plotly_chart(fig2a, use_container_width=True)
                    
                    with tab2:
                        # Simple provider summary for the overview tab
                        provider_summary = filtered_df.groupby('Provider')['Amount'].agg(['sum', 'count'])\
                            .nlargest(10, 'sum')\
                            .reset_index()
                        
                        # Display provider summary in a clean format
                        st.markdown("**Top 10 Providers by Deduction Amount**")
                        
                        # Create a clean table with metrics
                        cols = st.columns([5, 3, 2])
                        with cols[0]: st.markdown("**Provider**")
                        with cols[1]: st.markdown("**Total Amount**")
                        with cols[2]: st.markdown("**#**")
                        
                        for _, row in provider_summary.iterrows():
                            col1, col2, col3 = st.columns([5, 3, 2])
                            with col1:
                                st.markdown(f"{row['Provider']}")
                            with col2:
                                st.text(f"${row['sum']:,.2f}")
                            with col3:
                                st.text(f"{row['count']:,}")
                        
                        # Add a simple bar chart for visualization
                        st.markdown("---")
                        st.markdown("**Provider Distribution**")
                        fig2b = px.bar(
                            provider_summary.head(5),  # Show top 5 for better readability
                            x='Provider',
                            y='sum',
                            labels={'sum': 'Total Amount ($)', 'Provider': ''},
                            template='plotly_white',
                            height=300
                        )
                        fig2b.update_layout(
                            xaxis_tickangle=-45,
                            showlegend=False,
                            margin=dict(t=0, b=100, l=0, r=0)
                        )
                        st.plotly_chart(fig2b, use_container_width=True)
                        
                        # Transaction Explorer button removed as requested
            
            # Second row of charts
            st.markdown("#### Top Employers by Deduction Amount")
            if 'Employer' in filtered_df.columns and 'Amount' in filtered_df.columns:
                top_employers = filtered_df.groupby('Employer')['Amount'].sum().nlargest(10).reset_index()
                
                fig = px.bar(
                    top_employers,
                    x='Amount',
                    y='Employer',
                    orientation='h',
                    title='Top 10 Employers by Deduction Amount',
                    labels={'Amount': 'Total Amount ($)', 'Employer': ''},
                    color='Amount',
                    color_continuous_scale='Viridis'
                )
                
                fig.update_layout(
                    xaxis_title='Total Amount ($)',
                    yaxis={'categoryorder': 'total ascending'},
                    height=500,
                    coloraxis_showscale=False
                )
                
                st.plotly_chart(fig, use_container_width=True)
            
            # Removed Provider Performance section - moved to Transaction Explorer tab
        
        with tab2:
            st.markdown("### 🔍 Transaction Explorer")
            
            # Check if we need to refresh the explorer view
            if st.session_state.get('force_explorer_refresh', False):
                st.session_state.force_explorer_refresh = False
                st.experimental_rerun()
            
            # Check if we have a provider filter from the Overview tab
            if st.session_state.selected_provider:
                st.info(f"Showing transactions for provider: {st.session_state.selected_provider}")
                if st.button("Clear filter"):
                    st.session_state.selected_provider = None
                    st.experimental_rerun()
                    
            # Display transaction explorer content
            if df.empty:
                st.warning("No transaction data available. Please upload a file first.")
                return
            
            # Transaction Explorer content starts here (Provider Analysis section removed)
                
            # Add filters
            st.markdown("#### Filters")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                status_options = df['Status'].unique() if 'Status' in df.columns else []
                status_filter = st.multiselect(
                    "Status",
                    options=status_options,
                    default=[]
                )
            
            with col2:
                provider_options = df['Provider'].unique() if 'Provider' in df.columns else []
                # If we have a selected provider from the Overview tab, use it as the default
                default_provider = [st.session_state.selected_provider] if st.session_state.selected_provider else []
                provider_filter = st.multiselect(
                    "Provider",
                    options=provider_options,
                    default=default_provider
                )
            
            with col3:
                min_amt = float(df['Amount'].min()) if 'Amount' in df.columns else 0
                max_amt = float(df['Amount'].max()) if 'Amount' in df.columns else 1000
                min_amount, max_amount = st.slider(
                    "Deduction Amount Range",
                    min_value=min_amt,
                    max_value=max_amt,
                    value=(min_amt, max_amt)
                )
            
            # Apply filters
            filtered_data = df.copy()
            if status_filter:
                filtered_data = filtered_data[filtered_data['Status'].isin(status_filter)]
            if provider_filter:
                filtered_data = filtered_data[filtered_data['Provider'].isin(provider_filter)]
            if 'Amount' in filtered_data.columns:
                filtered_data = filtered_data[
                    (filtered_data['Amount'] >= min_amount) & 
                    (filtered_data['Amount'] <= max_amount)
                ]
            
            # Show metrics for the filtered data
            if not filtered_data.empty:
                st.metric("Total Transactions", len(filtered_data))
                st.metric("Total Amount", f"${filtered_data['Amount'].sum():,.2f}" if 'Amount' in filtered_data.columns else "N/A")
            
            # Sorting options
            st.markdown("#### Sort & Pagination")
            col1, col2 = st.columns(2)
            
            with col1:
                sort_by = st.selectbox(
                    "Sort by",
                    ['Deduction Submission Date', 'Amount', 'Status', 'Provider'],
                    index=0
                )
            
            with col2:
                sort_order = st.radio("Sort order", ["Descending", "Ascending"], horizontal=True)
            
            filtered_data = filtered_data.sort_values(
                by=sort_by,
                ascending=(sort_order == "Ascending"),
                na_position='last'
            )
            
            # Display data table with pagination
            if not filtered_data.empty:
                page_size = 10
                total_pages = (len(filtered_data) // page_size) + (1 if len(filtered_data) % page_size > 0 else 0)
                page_number = st.number_input("Page", min_value=1, max_value=max(total_pages, 1), value=1)
                start_idx = (page_number - 1) * page_size
                end_idx = start_idx + page_size
                
                # Display the current page of data
                st.dataframe(
                    filtered_data.iloc[start_idx:end_idx],
                    use_container_width=True,
                    hide_index=True
                )
                
                # Add export button
                csv = filtered_data.to_csv(index=False).encode('utf-8')
                st.download_button(
                    "Export Filtered Data",
                    data=csv,
                    file_name=f"deductions_export_{datetime.datetime.now().strftime('%Y%m%d')}.csv",
                    mime='text/csv',
                    key='download_csv',
                    use_container_width=True
                )
            else:
                st.warning("No data matches the selected filters.")
            
            # Clear the selected provider after displaying
            if st.session_state.selected_provider:
                st.session_state.selected_provider = None
        
        with tab3:
            st.markdown("### 📈 Advanced Analytics")
            
            # Performance Metrics
            st.markdown("#### Performance Metrics")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                # Success rate by provider
                if all(col in df.columns for col in ['Provider', 'Status', 'Amount']):
                    provider_perf = df.groupby('Provider').agg(
                        total_amount=('Amount', 'sum'),
                        success_rate=('Status', lambda x: (x == 'Successful').mean() * 100),
                        avg_amount=('Amount', 'mean')
                    ).reset_index()
                    
                    st.metric("Top Performing Provider", 
                             provider_perf.nlargest(1, 'total_amount')['Provider'].values[0] if not provider_perf.empty else "N/A",
                             f"${provider_perf['total_amount'].max():,.2f}" if not provider_perf.empty else "$0.00")
            
            with col2:
                if not provider_perf.empty:
                    avg_success_rate = provider_perf['success_rate'].mean()
                    st.metric("Average Success Rate", f"{avg_success_rate:.1f}%")
            
            with col3:
                if 'Failed Amount' in df.columns:
                    recovery_rate = (1 - (df['Failed Amount'].sum() / df['Amount'].sum())) * 100
                    st.metric("Recovery Rate", f"{recovery_rate:.1f}%")
            
            # Time-based analysis
            st.markdown("#### Time-Based Analysis")
            
            if 'Deduction Submission Date' in df.columns and 'Amount' in df.columns:
                # Weekly patterns
                df['DayOfWeek'] = df['Deduction Submission Date'].dt.day_name()
                df['Hour'] = df['Deduction Submission Date'].dt.hour
                
                # Day of week analysis
                day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
                weekly_pattern = df.groupby('DayOfWeek')['Amount'].sum().reindex(day_order).reset_index()
                
                fig_weekly = px.bar(
                    weekly_pattern,
                    x='DayOfWeek',
                    y='Amount',
                    title='Deduction Amount by Day of Week',
                    labels={'Amount': 'Total Amount ($)', 'DayOfWeek': 'Day of Week'},
                    template='plotly_white'
                )
                
                # Hourly pattern
                hourly_pattern = df.groupby('Hour')['Amount'].sum().reset_index()
                
                fig_hourly = px.line(
                    hourly_pattern,
                    x='Hour',
                    y='Amount',
                    title='Deduction Amount by Hour of Day',
                    labels={'Amount': 'Total Amount ($)', 'Hour': 'Hour of Day'},
                    template='plotly_white',
                    markers=True
                )
                
                # Display charts
                col1, col2 = st.columns(2)
                with col1:
                    st.plotly_chart(fig_weekly, use_container_width=True)
                with col2:
                    st.plotly_chart(fig_hourly, use_container_width=True)
            
            # Provider Performance
            st.markdown("#### Provider Performance")
            
            if all(col in df.columns for col in ['Provider', 'Status', 'Amount']):
                # Top 10 providers by amount
                top_providers = df.groupby('Provider').agg(
                    total_amount=('Amount', 'sum'),
                    success_rate=('Status', lambda x: (x == 'Successful').mean() * 100),
                    avg_amount=('Amount', 'mean'),
                    count=('Amount', 'count')
                ).nlargest(10, 'total_amount').reset_index()
                
                # Create a bar chart with success rate as line
                fig_providers = go.Figure()
                
                # Bar chart for total amount
                fig_providers.add_trace(
                    go.Bar(
                        x=top_providers['Provider'],
                        y=top_providers['total_amount'],
                        name='Total Amount',
                        marker_color='#1f77b4'
                    )
                )
                
                # Line chart for success rate (secondary y-axis)
                fig_providers.add_trace(
                    go.Scatter(
                        x=top_providers['Provider'],
                        y=top_providers['success_rate'],
                        name='Success Rate %',
                        yaxis='y2',
                        line=dict(color='#ff7f0e', width=2)
                    )
                )
                
                # Update layout for dual y-axes
                fig_providers.update_layout(
                    title='Top 10 Providers by Deduction Amount',
                    xaxis_title='Provider',
                    yaxis_title='Total Amount ($)',
                    yaxis2=dict(
                        title='Success Rate (%)',
                        overlaying='y',
                        side='right',
                        range=[0, 100]  # Percentage range
                    ),
                    legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1),
                    template='plotly_white'
                )
                
                st.plotly_chart(fig_providers, use_container_width=True)
                
                # Show provider performance table
                st.markdown("**Provider Performance Metrics**")
                st.dataframe(
                    top_providers.rename(columns={
                        'total_amount': 'Total Amount ($)',
                        'success_rate': 'Success Rate (%)',
                        'avg_amount': 'Avg. Amount ($)',
                        'count': 'Transaction Count'
                    }),
                    use_container_width=True,
                    hide_index=True
                )
            
            # Time Series Analysis Section
            st.markdown("### Time Series Analysis")
            
            if 'Deduction Submission Date' in df.columns and 'Amount' in df.columns:
                # Resample data by week
                time_series = df.set_index('Deduction Submission Date')['Amount'].resample('W').sum().reset_index()
                
                # Calculate moving averages
                time_series['7D_MA'] = time_series['Amount'].rolling(window=4, min_periods=1).mean()
                time_series['30D_MA'] = time_series['Amount'].rolling(window=12, min_periods=1).mean()
                
                # Create the time series chart
                fig = go.Figure()
                
                # Add actual values
                fig.add_trace(go.Scatter(
                    x=time_series['Deduction Submission Date'],
                    y=time_series['Amount'],
                    mode='lines+markers',
                    name='Weekly Total',
                    line=dict(color='#1f77b4')
                ))
                
                # Add moving averages
                fig.add_trace(go.Scatter(
                    x=time_series['Deduction Submission Date'],
                    y=time_series['7D_MA'],
                    mode='lines',
                    name='4-Week Moving Avg',
                    line=dict(color='#ff7f0e', dash='dash')
                ))
                
                fig.add_trace(go.Scatter(
                    x=time_series['Deduction Submission Date'],
                    y=time_series['30D_MA'],
                    mode='lines',
                    name='12-Week Moving Avg',
                    line=dict(color='#2ca02c', dash='dot')
                ))
                
                fig.update_layout(
                    title='Deduction Amounts Over Time with Moving Averages',
                    xaxis_title='Date',
                    yaxis_title='Amount ($)',
                    hovermode='x unified',
                    height=500
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Anomaly Detection
                st.markdown("### Anomaly Detection")
                
                # Simple Z-score based anomaly detection
                time_series['zscore'] = (time_series['Amount'] - time_series['Amount'].mean()) / time_series['Amount'].std()
                anomalies = time_series[abs(time_series['zscore']) > 2]
                
                if not anomalies.empty:
                    st.warning(f"⚠️ Detected {len(anomalies)} potential anomalies in the data")
                    
                    # Create anomaly chart
                    anomaly_fig = go.Figure()
                    
                    # Add normal points
                    normal = time_series[abs(time_series['zscore']) <= 2]
                    anomaly_fig.add_trace(go.Scatter(
                        x=normal['Deduction Submission Date'],
                        y=normal['Amount'],
                        mode='markers',
                        name='Normal',
                        marker=dict(color='blue')
                    ))
                    
                    # Add anomalies
                    anomaly_fig.add_trace(go.Scatter(
                        x=anomalies['Deduction Submission Date'],
                        y=anomalies['Amount'],
                        mode='markers',
                        name='Anomaly',
                        marker=dict(color='red', size=10, line=dict(width=2, color='DarkRed'))
                    ))
                    
                    anomaly_fig.update_layout(
                        title='Detected Anomalies in Deduction Amounts',
                        xaxis_title='Date',
                        yaxis_title='Amount ($)',
                        height=400
                    )
                    
                    st.plotly_chart(anomaly_fig, use_container_width=True)
                    
                    # Show anomaly details
                    with st.expander("View Anomaly Details"):
                        anomaly_display = anomalies[['Deduction Submission Date', 'Amount', 'zscore']].copy()
                        anomaly_display['Deviation'] = (anomaly_display['zscore'].abs() * 100).round(2).astype(str) + '% from mean'
                        anomaly_display = anomaly_display.rename(columns={
                            'Deduction Submission Date': 'Date',
                            'Amount': 'Deduction Amount',
                            'zscore': 'Z-Score'
                        })
                        st.dataframe(anomaly_display, hide_index=True, use_container_width=True)
                else:
                    st.success("✅ No significant anomalies detected in the data")
            
            # Correlation Analysis
            st.markdown("### Correlation Analysis")
            
            if len(df.select_dtypes(include=['number']).columns) > 1:
                # Select numeric columns for correlation
                numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
                
                if len(numeric_cols) >= 2:
                    # Calculate correlation matrix
                    corr = df[numeric_cols].corr()
                    
                    # Create heatmap
                    fig = px.imshow(
                        corr,
                        text_auto=True,
                        aspect="auto",
                        color_continuous_scale='RdBu',
                        zmin=-1,
                        zmax=1,
                        title='Correlation Matrix of Numeric Variables'
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Show top correlations
                    st.markdown("#### Top Correlations")
                    
                    # Get upper triangle of correlation matrix
                    corr = corr.mask(np.triu(np.ones_like(corr, dtype=bool)))
                    
                    # Unstack and sort correlations
                    corr_pairs = corr.unstack().sort_values(ascending=False)
                    
                    # Create a DataFrame of correlations
                    corr_df = pd.DataFrame(corr_pairs, columns=['Correlation']).reset_index()
                    corr_df = corr_df[corr_df['Correlation'] != 1]  # Remove self-correlations
                    corr_df = corr_df.dropna()
                    
                    if not corr_df.empty:
                        top_correlations = corr_df.head(10)
                        
                        # Create a bar chart of top correlations
                        fig = px.bar(
                            top_correlations,
                            x='Correlation',
                            y=top_correlations['level_0'] + ' & ' + top_correlations['level_1'],
                            orientation='h',
                            title='Top Variable Correlations',
                            labels={'Correlation': 'Correlation Coefficient', 'y': 'Variable Pairs'}
                        )
                        
                        fig.update_layout(yaxis={'categoryorder':'total ascending'}, height=400)
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info("No significant correlations found between numeric variables.")
                else:
                    st.warning("Need at least two numeric columns for correlation analysis.")
            else:
                st.warning("Not enough numeric data for correlation analysis.")
            
            # Advanced Filtering
            st.markdown("### Advanced Data Exploration")
            
            # Dynamic filters
            st.markdown("#### Apply Filters")
            
            filter_cols = st.columns(3)
            filters = {}
            
            # Get unique values for filtering
            categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
            numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
            
            # Add categorical filters
            for i, col in enumerate(categorical_cols[:3]):  # Show first 3 categorical columns
                with filter_cols[i % 3]:
                    unique_vals = df[col].unique().tolist()
                    if len(unique_vals) > 1:  # Only show if there's more than one unique value
                        selected = st.multiselect(f"Filter by {col}", options=unique_vals, key=f"filter_{col}")
                        if selected:
                            filters[col] = selected
            
            # Add numeric range filters
            st.markdown("#### Numeric Ranges")
            range_cols = st.columns(2)
            
            for i, col in enumerate(numeric_cols[:4]):  # Show first 4 numeric columns
                with range_cols[i % 2]:
                    min_val = float(df[col].min())
                    max_val = float(df[col].max())
                    
                    # Create a range slider
                    values = st.slider(
                        f"{col} Range",
                        min_value=min_val,
                        max_value=max_val,
                        value=(min_val, max_val),
                        key=f"range_{col}"
                    )
                    
                    filters[f"{col}_min"] = values[0]
                    filters[f"{col}_max"] = values[1]
            
            # Apply filters
            filtered_df = df.copy()
            
            # Apply categorical filters
            for col, values in filters.items():
                if col in categorical_cols:
                    filtered_df = filtered_df[filtered_df[col].isin(values)]
                elif col.endswith('_min') and col.replace('_min', '') in numeric_cols:
                    col_name = col.replace('_min', '')
                    filtered_df = filtered_df[filtered_df[col_name] >= values]
                elif col.endswith('_max') and col.replace('_max', '') in numeric_cols:
                    col_name = col.replace('_max', '')
                    filtered_df = filtered_df[filtered_df[col_name] <= values]
            
            # Show filtered data
            st.markdown(f"#### Filtered Data ({len(filtered_df)} rows)")
            st.dataframe(filtered_df, use_container_width=True)
            
            # Export filtered data
            st.download_button(
                label="Download Filtered Data (CSV)",
                data=filtered_df.to_csv(index=False).encode('utf-8'),
                file_name='filtered_deductions.csv',
                mime='text/csv',
                key='download_filtered_data'
            )

if __name__ == "__main__":
    main()
